{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hemil19/DataScience-3/blob/master/household_load_forecasting_CNN_LSTM_Copy1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61254eef",
      "metadata": {
        "id": "61254eef"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import math\n",
        "import datetime\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout,Conv1D,Flatten,MaxPooling1D,Input,TimeDistributed\n",
        "from numpy import concatenate\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ac05b80",
      "metadata": {
        "id": "2ac05b80"
      },
      "outputs": [],
      "source": [
        "#reading the csv file into pandas data frame\n",
        "data = pd.read_csv(\"household_power_consumption.csv\")\n",
        "#setting the Date column as the index of the data frame\n",
        "data['datetime'] = data['datetime'].apply(pd.to_datetime)\n",
        "data.set_index('datetime',inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "355cd756",
      "metadata": {
        "id": "355cd756"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c21de78b",
      "metadata": {
        "id": "c21de78b"
      },
      "outputs": [],
      "source": [
        "data=data.resample(\"M\").sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06c08345",
      "metadata": {
        "id": "06c08345"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe3943c0",
      "metadata": {
        "id": "fe3943c0"
      },
      "outputs": [],
      "source": [
        "#check the quantity of null values in each columns\n",
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9c4029f",
      "metadata": {
        "id": "e9c4029f"
      },
      "outputs": [],
      "source": [
        "data.values[:,:-1]\n",
        "data.values[:,-1].reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b80b424",
      "metadata": {
        "id": "6b80b424"
      },
      "outputs": [],
      "source": [
        "#scale the values\n",
        "dataset = data.values\n",
        "scaler1 = MinMaxScaler(feature_range=(0, 1))\n",
        "dataset1 = scaler1.fit_transform(data.values[:,:-1])\n",
        "scaler2 = MinMaxScaler(feature_range=(0, 1))\n",
        "dataset2 = scaler2.fit_transform(data.values[:,-1].reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e67c48f",
      "metadata": {
        "id": "8e67c48f"
      },
      "outputs": [],
      "source": [
        "dataset1.shape,dataset2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f9b6a3f",
      "metadata": {
        "id": "9f9b6a3f"
      },
      "outputs": [],
      "source": [
        "data.values[:,-1].reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d445cf3",
      "metadata": {
        "id": "7d445cf3"
      },
      "outputs": [],
      "source": [
        "np.concatenate([dataset1, data.values[:,-1].reshape(-1,1)],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42deedda",
      "metadata": {
        "id": "42deedda"
      },
      "outputs": [],
      "source": [
        "dataset=np.concatenate([dataset1, data.values[:,-1].reshape(-1,1)], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "874c04ad",
      "metadata": {
        "id": "874c04ad"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96556bd8",
      "metadata": {
        "id": "96556bd8"
      },
      "outputs": [],
      "source": [
        "#divide the data into train and test data\n",
        "train_size = int(len(dataset) * 0.80)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f80c5447",
      "metadata": {
        "id": "f80c5447"
      },
      "outputs": [],
      "source": [
        "train.shape,test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3be6b760",
      "metadata": {
        "id": "3be6b760"
      },
      "outputs": [],
      "source": [
        "def split_sequences(sequences, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequences)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the dataset\n",
        "\t\tif end_ix > len(sequences):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e85a1528",
      "metadata": {
        "id": "e85a1528"
      },
      "outputs": [],
      "source": [
        "n_steps=5\n",
        "n_features=7\n",
        "X_train,y_train=split_sequences(train,n_steps)\n",
        "X_test,y_test=split_sequences(test,n_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cd27af0",
      "metadata": {
        "id": "5cd27af0"
      },
      "outputs": [],
      "source": [
        "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f862619d",
      "metadata": {
        "id": "f862619d"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE=2\n",
        "TRAIN_STEP = math.ceil(X_train.shape[0] / BATCH_SIZE)\n",
        "VALIDATION_STEP = math.ceil(X_test.shape[0] / BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edc16278",
      "metadata": {
        "id": "edc16278"
      },
      "outputs": [],
      "source": [
        "for i in range(2):\n",
        "\tprint(X_train[i], y_train[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60e0f59a",
      "metadata": {
        "id": "60e0f59a"
      },
      "outputs": [],
      "source": [
        "X_train.shape[-2:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3ca71e7",
      "metadata": {
        "id": "b3ca71e7"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv1D(filters=64,\n",
        "                           kernel_size=5,\n",
        "                           strides=1,\n",
        "                           padding=\"causal\",\n",
        "                           activation=\"relu\",\n",
        "                           input_shape=X_train.shape[-2:]),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2, strides=1, padding=\"valid\"),\n",
        "    tf.keras.layers.Conv1D(filters=32, kernel_size=3, strides=1, padding=\"causal\", activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2, strides=1, padding=\"valid\"),\n",
        "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
        "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(1e-4,\n",
        "                                                             decay_steps=100000,\n",
        "                                                             decay_rate=0.98,\n",
        "                                                             staircase=False)\n",
        "\n",
        "model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "              optimizer=tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.8),\n",
        "              metrics=['mae'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbeb82f3",
      "metadata": {
        "id": "bbeb82f3"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train, \n",
        "                    epochs=500, \n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    steps_per_epoch=TRAIN_STEP,\n",
        "                    validation_data=(X_test,y_test),\n",
        "                    validation_steps=VALIDATION_STEP,\n",
        "                    verbose=2, \n",
        "                    shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fad353a",
      "metadata": {
        "id": "3fad353a"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a134b41",
      "metadata": {
        "id": "7a134b41"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9e8133d",
      "metadata": {
        "id": "e9e8133d"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc582464",
      "metadata": {
        "id": "cc582464"
      },
      "outputs": [],
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=1, activation='relu', input_shape=(n_steps, n_features)))\n",
        "model.add(MaxPooling1D(pool_size=1))\n",
        "model.add(LSTM(10))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e335a213",
      "metadata": {
        "id": "e335a213"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train, epochs=250, batch_size=10, validation_data=(X_test,y_test), verbose=2, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cd62994",
      "metadata": {
        "id": "5cd62994"
      },
      "outputs": [],
      "source": [
        "# model1 = Sequential()\n",
        "# model1.add(Conv1D(500, kernel_size=2, input_shape=(train_X.shape[1],train_X.shape[2])))\n",
        "# model1.add(MaxPooling1D(pool_size=1))\n",
        "# model1.add(LSTM(10))\n",
        "# model1.add(Dense(100))\n",
        "# model1.add(Dense(1,activation='sigmoid'))\n",
        "# model1.compile(loss='mae', optimizer='adam')\n",
        "# print(model1.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc953219",
      "metadata": {
        "id": "bc953219"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78bf1372",
      "metadata": {
        "id": "78bf1372"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cde8c26",
      "metadata": {
        "id": "6cde8c26"
      },
      "outputs": [],
      "source": [
        "#prediction on training and testing data\n",
        "train_predict = model.predict(X_train)  \n",
        "test_predict = model.predict(X_test)       \n",
        "\n",
        "# #converting from three dimension to two dimension\n",
        "# train_X = train_X.reshape((X_train.shape[0], X_train.shape[2]))\n",
        "# test_X = test_X.reshape((X_test.shape[0], X_test.shape[2]))\n",
        "\n",
        "# inv_train_predict = concatenate((train_predict, X_train), axis=1)\n",
        "# inv_test_predict = concatenate((test_predict, X_test), axis=1)\n",
        "\n",
        "# #transforming to original scale\n",
        "# inv_train_predict = scaler.inverse_transform(inv_train_predict)\n",
        "# inv_test_predict = scaler.inverse_transform(inv_test_predict)\n",
        "\n",
        "# #predicted values on training data\n",
        "# inv_train_predict = inv_train_predict[:,0]\n",
        "# print(\"Train Predicted Values:\",inv_train_predict)\n",
        "\n",
        "# #predicted values on testing data\n",
        "# inv_test_predict = inv_test_predict[:,0] \n",
        "# print(\"Test Predicted Values:\",inv_test_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88efc473",
      "metadata": {
        "id": "88efc473"
      },
      "outputs": [],
      "source": [
        "train_predict.shape,test_predict.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0268ccf",
      "metadata": {
        "id": "b0268ccf"
      },
      "outputs": [],
      "source": [
        "actual=scaler2.inverse_transform(y_test.reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4298f1aa",
      "metadata": {
        "id": "4298f1aa"
      },
      "outputs": [],
      "source": [
        "pred=scaler2.inverse_transform(test_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2872f618",
      "metadata": {
        "id": "2872f618"
      },
      "outputs": [],
      "source": [
        "actual.shape,pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0624e76",
      "metadata": {
        "id": "d0624e76"
      },
      "outputs": [],
      "source": [
        "df=pd.DataFrame()\n",
        "df['index']=[i for i in range(actual.shape[0])][:30]\n",
        "df['actual']=actual[:30]\n",
        "df['predicted']=pred[:30]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9828db1",
      "metadata": {
        "id": "b9828db1"
      },
      "outputs": [],
      "source": [
        "mape=np.sum(np.abs((df['actual']-df['predicted'])/df['actual']))/len(df)\n",
        "mape*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "393487b9",
      "metadata": {
        "id": "393487b9"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(25, 10))\n",
        "#plt.plot(train_date, inv_train_predict,label=\"actual_train\")\n",
        "plt.plot(df['index'], df['predicted'], color='r',label=\"predicted\")\n",
        "plt.plot(df['index'], df['actual'], color='b',label=\"actual_test\")\n",
        "plt.legend(loc='best', fontsize='xx-large')\n",
        "plt.xticks(fontsize=18)\n",
        "plt.yticks(fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1a52e44",
      "metadata": {
        "id": "d1a52e44"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "household load forecasting-CNN-LSTM-Copy1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}